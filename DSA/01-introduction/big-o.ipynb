{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Big O Notation\n",
    "\n",
    "Here we use pytest and test driven development to understand the time complexity of an algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting solutions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile solutions.py\n",
    "import pytest\n",
    "\n",
    "class Solution():\n",
    "    def find_max(self, nums: list[int]) -> int:\n",
    "        \"\"\"\n",
    "        Psuedocode:\n",
    "        1. if nums is empty, return None\n",
    "        2. enumerate nums\n",
    "        3. if i == 0, set maxNum = num (first element)\n",
    "        4. if num > maxNum, set maxNum = num (2 to last element)\n",
    "        5. return maxNum\n",
    "        \"\"\"\n",
    "        if not nums:\n",
    "            return None\n",
    "        for i, num in enumerate(nums):\n",
    "            if i == 0:\n",
    "                maxNum = num\n",
    "            elif num > maxNum:\n",
    "                maxNum = num\n",
    "        return maxNum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_solutions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_solutions.py\n",
    "from solutions import Solution\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def solution():\n",
    "    return Solution()\n",
    "\n",
    "def test_positive(solution):\n",
    "    assert solution.find_max([1,2,3,4,5]) == 5\n",
    "\n",
    "def test_negative(solution):\n",
    "    assert solution.find_max([-1,-2,-3,-4,-5]) == -1\n",
    "\n",
    "def test_negative_positive(solution):\n",
    "    assert solution.find_max([-2,-1,0,+1,+2]) == 2\n",
    "\n",
    "def test_same(solution):\n",
    "    assert solution.find_max([0,0,0,0,0]) == 0\n",
    "\n",
    "def test_empty(solution):\n",
    "    assert solution.find_max([]) == None\n",
    "\n",
    "def test_single(solution):\n",
    "    assert solution.find_max([10]) == 10\n",
    "\n",
    "def test_same_positive(solution):\n",
    "    assert solution.find_max([7,7,7,7,7,7]) == 7\n",
    "\n",
    "def test_large_positive(solution):\n",
    "    assert solution.find_max([1000000, 2000000, 3000000]) == 3000000\n",
    "\n",
    "def test_large_negative(solution):\n",
    "    assert solution.find_max([-1000000, -2000000, -3000000]) == -1000000\n",
    "\n",
    "def test_large_mixed_large_small(solution):\n",
    "    assert solution.find_max([-1000000, 1000000, -0.00001, 0, 0.00001, 999999, -999999]) == 1000000\n",
    "\n",
    "def test_floats(solution):\n",
    "    assert solution.find_max([1.5,2.5,-3.5,0.5]) == 2.5\n",
    "\n",
    "def test_duplicates(solution):\n",
    "    assert solution.find_max([1,2,2,3,1,-1,-2,-3,3]) == 3\n",
    "\n",
    "def test_reversed_sorted_list(solution):\n",
    "    assert solution.find_max([9, 8, 7, 6, 5, 4, 3, 2, 1]) == 9\n",
    "\n",
    "def test_long_list(solution):\n",
    "    long_list = list(range(-100000, 100000))  # A list with 200,000 elements\n",
    "    assert solution.find_max(long_list) == 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m14 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q --tb=short test_solutions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_time.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_time.py\n",
    "import time\n",
    "from solutions import Solution\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def solution():\n",
    "    return Solution()\n",
    "\n",
    "def test_time_small_input(solution):\n",
    "    small_list = list(range(1000))  # Small input size\n",
    "    start_time = time.time()\n",
    "    solution.find_max(small_list)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Time taken for small input: {execution_time} seconds\")\n",
    "    assert execution_time < 0.1  # Ensure it finishes in less than 100ms\n",
    "\n",
    "def test_time_medium_input(solution):\n",
    "    medium_list = list(range(100000))  # Medium input size\n",
    "    start_time = time.time()\n",
    "    solution.find_max(medium_list)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Time taken for medium input: {execution_time} seconds\")\n",
    "    assert execution_time < 0.5  # Ensure it finishes in less than 500ms\n",
    "\n",
    "def test_time_large_input(solution):\n",
    "    large_list = list(range(10000000))  # Large input size\n",
    "    start_time = time.time()\n",
    "    solution.find_max(large_list)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Time taken for large input: {execution_time} seconds\")\n",
    "    assert execution_time < 1.0  # Ensure it finishes in less than 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 0.52s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q --tb=short test_time.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_benchmark.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_benchmark.py\n",
    "import time\n",
    "from solutions import Solution\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def solution():\n",
    "    return Solution()\n",
    "\n",
    "# Pytest Benchmark for small input\n",
    "def test_benchmark_small_input(solution,benchmark):\n",
    "    small_list = list(range(1000))  # Small input size\n",
    "    benchmark(solution.find_max, small_list)\n",
    "\n",
    "# Pytest Benchmark for medium input\n",
    "def test_benchmark_medium_input(solution,benchmark):\n",
    "    medium_list = list(range(100000))  # Medium input size\n",
    "    benchmark(solution.find_max, medium_list)\n",
    "\n",
    "# Pytest Benchmark for large input\n",
    "def test_benchmark_large_input(solution,benchmark):\n",
    "    large_list = list(range(10000000))  # Large input size\n",
    "    benchmark(solution.find_max, large_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m------------------------------------------------------------------------------------------------------ benchmark: 3 tests -----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Name (time in us)                        Min                     Max                    Mean                StdDev                  Median                   IQR            Outliers          OPS            Rounds  Iterations\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "test_benchmark_small_input    \u001b[32m\u001b[1m       28.2080 (1.0)    \u001b[0m\u001b[32m\u001b[1m      854.6070 (1.0)    \u001b[0m\u001b[32m\u001b[1m       30.8282 (1.0)    \u001b[0m\u001b[32m\u001b[1m     12.4370 (1.0)    \u001b[0m\u001b[32m\u001b[1m       29.4560 (1.0)    \u001b[0m\u001b[32m\u001b[1m      1.2050 (1.0)    \u001b[0m  568;2804\u001b[32m\u001b[1m  32,437.8421 (1.0)    \u001b[0m   28448           1\n",
      "test_benchmark_medium_input   \u001b[1m    2,922.4120 (103.60) \u001b[0m\u001b[1m    8,239.9930 (9.64)   \u001b[0m\u001b[1m    3,171.9708 (102.89) \u001b[0m\u001b[1m    375.2770 (30.17)  \u001b[0m\u001b[1m    3,076.1175 (104.43) \u001b[0m\u001b[1m    204.4290 (169.65) \u001b[0m     22;25\u001b[1m     315.2614 (0.01)   \u001b[0m     320           1\n",
      "test_benchmark_large_input    \u001b[31m\u001b[1m  315,270.0340 (>1000.0)\u001b[0m\u001b[31m\u001b[1m  332,132.1270 (388.64) \u001b[0m\u001b[31m\u001b[1m  319,778.6654 (>1000.0)\u001b[0m\u001b[31m\u001b[1m  7,028.3890 (565.12) \u001b[0m\u001b[31m\u001b[1m  316,569.7990 (>1000.0)\u001b[0m\u001b[31m\u001b[1m  6,231.9875 (>1000.0)\u001b[0m       1;1\u001b[31m\u001b[1m       3.1272 (0.00)   \u001b[0m       5           1\n",
      "\u001b[33m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "Legend:\n",
      "  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.\n",
      "  OPS: Operations Per Second, computed as 1 / Mean\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 5.36s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q --tb=short test_benchmark.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting solutions.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile solutions.c\n",
    "#include <stdio.h>\n",
    "#include <limits.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "\n",
    "int find_max(int *nums, int size) {\n",
    "    if (size == 0) {\n",
    "        return INT_MIN;  // Return INT_MIN if array is empty\n",
    "    }\n",
    "\n",
    "    int max_num = nums[0];  // Initialize with the first element\n",
    "\n",
    "    for (int i = 1; i < size; i++) {\n",
    "        if (nums[i] > max_num) {\n",
    "            max_num = nums[i];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return max_num;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "    int size = 1000;  // Default size, can be modified based on input\n",
    "    if (argc > 1) {\n",
    "        sscanf(argv[1], \"%d\", &size);  // Get size from command-line argument\n",
    "    }\n",
    "\n",
    "    // Dynamically allocate memory for the array to handle large input sizes\n",
    "    int *nums = (int *)malloc(size * sizeof(int));\n",
    "    if (nums == NULL) {\n",
    "        printf(\"Memory allocation failed!\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    // Fill array with values 0, 1, 2, ..., size-1\n",
    "    for (int i = 0; i < size; i++) {\n",
    "        nums[i] = i;\n",
    "    }\n",
    "\n",
    "    clock_t start = clock();\n",
    "    int max_value = find_max(nums, size);\n",
    "    clock_t end = clock();\n",
    "\n",
    "    double time_taken = ((double)(end - start)) / CLOCKS_PER_SEC;\n",
    "\n",
    "    printf(\"Max Value: %d\\n\", max_value);\n",
    "    printf(\"Time taken: %f seconds\\n\", time_taken);\n",
    "\n",
    "    // Free the allocated memory\n",
    "    free(nums);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_benchmark_c.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_benchmark_c.py\n",
    "import subprocess\n",
    "import pytest\n",
    "\n",
    "# Helper function to run the C program with in-memory data\n",
    "def run_c_program(input_size):\n",
    "    # Call the C program with the input size as a command-line argument\n",
    "    result = subprocess.run(['./solutions', str(input_size)], stdout=subprocess.PIPE)\n",
    "    \n",
    "    # Capture the output and split the lines\n",
    "    output_lines = result.stdout.decode('utf-8').strip().split('\\n')\n",
    "    \n",
    "    # The first line should contain the max value, so return only that\n",
    "    max_value = int(output_lines[0].split(': ')[1])  # Extract the integer value from \"Max Value: X\"\n",
    "    return max_value\n",
    "\n",
    "@pytest.mark.benchmark\n",
    "def test_benchmark_c_small_input(benchmark):\n",
    "    benchmark(run_c_program, 1000)  # Small input (1,000 elements)\n",
    "\n",
    "@pytest.mark.benchmark\n",
    "def test_benchmark_c_medium_input(benchmark):\n",
    "    benchmark(run_c_program, 100000)  # Medium input (100,000 elements)\n",
    "\n",
    "@pytest.mark.benchmark\n",
    "def test_benchmark_c_large_input(benchmark):\n",
    "    benchmark(run_c_program, 10000000)  # Large input (10,000,000 elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc -o solutions solutions.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m--------------------------------------------------------------------------------------------------- benchmark: 3 tests ---------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Name (time in us)                         Min                    Max                   Mean              StdDev                 Median                   IQR            Outliers         OPS            Rounds  Iterations\n",
      "\u001b[33m--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "test_benchmark_c_small_input    \u001b[32m\u001b[1m     266.2640 (1.0)    \u001b[0m\u001b[32m\u001b[1m     917.6770 (1.0)    \u001b[0m\u001b[32m\u001b[1m     314.9402 (1.0)    \u001b[0m\u001b[32m\u001b[1m   46.7061 (1.0)    \u001b[0m\u001b[32m\u001b[1m     303.7805 (1.0)    \u001b[0m\u001b[32m\u001b[1m     48.3520 (1.0)    \u001b[0m    152;47\u001b[32m\u001b[1m  3,175.2063 (1.0)    \u001b[0m    1464           1\n",
      "test_benchmark_c_medium_input   \u001b[1m     482.4290 (1.81)   \u001b[0m\u001b[1m   1,064.8940 (1.16)   \u001b[0m\u001b[1m     579.6611 (1.84)   \u001b[0m\u001b[1m   53.1418 (1.14)   \u001b[0m\u001b[1m     567.0520 (1.87)   \u001b[0m\u001b[1m     64.8905 (1.34)   \u001b[0m    372;44\u001b[1m  1,725.1458 (0.54)   \u001b[0m    1596           1\n",
      "test_benchmark_c_large_input    \u001b[31m\u001b[1m  18,250.4720 (68.54)  \u001b[0m\u001b[31m\u001b[1m  22,233.4860 (24.23)  \u001b[0m\u001b[31m\u001b[1m  20,739.1799 (65.85)  \u001b[0m\u001b[31m\u001b[1m  950.7004 (20.35)  \u001b[0m\u001b[31m\u001b[1m  20,947.0440 (68.95)  \u001b[0m\u001b[31m\u001b[1m  1,379.1440 (28.52)  \u001b[0m      16;0\u001b[31m\u001b[1m     48.2179 (0.02)   \u001b[0m      48           1\n",
      "\u001b[33m--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "Legend:\n",
      "  Outliers: 1 Standard Deviation from Mean; 1.5 IQR (InterQuartile Range) from 1st Quartile and 3rd Quartile.\n",
      "  OPS: Operations Per Second, computed as 1 / Mean\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 3.44s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -q --tb=short test_benchmark_c.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "Different systems have varying clock speeds, processing power, and memory architecture, which can impact the actual time taken for an algorithm to run. However, time complexity, represented using Big-O notation, provides an abstract way to measure algorithm efficiency, independent of the underlying hardware. This allows us to compare algorithms based on their growth rate as input size increases.\n",
    "\n",
    "In the benchmarks above, we observe that the time taken for the algorithm increases as the input size grows. This is consistent with the expected behavior of an algorithm with O(n) time complexity, where the execution time increases linearly as the input size increases. Both Python and C exhibit this linear growth, though C consistently performs faster due to its compiled nature and lower-level memory management, while Python’s interpreted nature introduces additional overhead.\n",
    "\n",
    "**Language Performance Differences:**\n",
    "\n",
    "C is a statically compiled language that operates closer to the hardware, offering more control over memory management and lower overhead, which results in faster execution for computationally intensive tasks.\n",
    "Python is an interpreted, high-level language that emphasizes ease of development and readability over raw performance. While it performs well for smaller inputs due to internal optimizations, its higher-level abstractions and memory overhead make it slower for large-scale operations compared to C.\n",
    "Time Complexity:\n",
    "Time complexity allows us to analyze the performance of an algorithm by describing how its runtime scales with the size of the input (denoted as n). This abstraction enables us to evaluate algorithms without worrying about the specific system they are running on, making it a crucial tool for comparing algorithmic efficiency across different platforms and languages.\n",
    "\n",
    "In this case, the algorithm we benchmarked exhibits O(n) time complexity, meaning that the runtime grows linearly with the input size. A linear time complexity indicates that if the input size doubles, the time taken to execute the algorithm roughly doubles as well.\n",
    "\n",
    "**Common Time Complexities:**\n",
    "\n",
    "1. O(1) – Constant Time Complexity: The algorithm’s runtime does not depend on the input size. It performs the same regardless of how large the input is. Example: Accessing an element in an array by index.\n",
    "\n",
    "2. O(log n) – Logarithmic Time Complexity: The algorithm’s runtime grows logarithmically as the input size increases. This often occurs in divide-and-conquer algorithms such as binary search, where the problem size is halved with each iteration.\n",
    "\n",
    "3. O(n) – Linear Time Complexity: The runtime increases proportionally with the input size. This is the case with our algorithm, where each element must be processed once.\n",
    "\n",
    "4. O(n log n) – Linear Logarithmic Time Complexity: This is typical of efficient sorting algorithms such as mergesort or heapsort, where the algorithm must perform n operations, but each operation involves a logarithmic number of steps.\n",
    "\n",
    "5. O(n^2) – Quadratic Time Complexity: The runtime grows quadratically as the input size increases. This is often seen in algorithms that involve nested loops, such as a basic implementation of bubble sort or selection sort.\n",
    "\n",
    "6. O(2^n) – Exponential Time Complexity: The runtime doubles with each additional element in the input, making it infeasible for large inputs. This is common in brute-force algorithms, such as solving the traveling salesman problem using recursion.\n",
    "\n",
    "7. O(n!) – Factorial Time Complexity: The runtime grows factorially with the input size, often seen in problems involving permutations or combinations, such as solving the traveling salesman problem via brute force.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Understanding the time complexity of algorithms is crucial when evaluating their performance, especially as input sizes grow. While system hardware and language implementation can affect runtime, time complexity provides a system-agnostic way to assess how an algorithm scales. Choosing the right algorithm based on time complexity can drastically improve performance, particularly in resource-intensive applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
